\section{Scrambling Algorithms}
\label{sec:scrambling_algorithms}

	Due to radiation levels inside the detector chamber, the main data processing takes place in a concrete bunker away from the detector, minimising radiation damage to the hardware.
	To facilitate this, optical linkes, 20 per modual, are used to transfer the data from the front end VELO to the Data Aquizition FPGA (DAQ).
	When comunicating data digitaly, the tranfering modual (TX) and the recieving modual (RX) must have syncrinised clocks.
	When achieving this, there are three main approunches:

	\begin{easylist}
		\ListProperties(Numbers=R,Margin=0.5cm,Align=fixed,FinalSpace=2em)
		& Syncinize both the TX and RX from a single central clock.
		& Transmit the TX clock to the RX modual.
		& Use bit-changes in the data to coninuesly sycnronise the RX clock.
	\end{easylist}

	The two former of these options, although the most convienient, are not appropriate for the VELO as they are suseptable to unforseens delays that could cause desyncronisation.
	The latter, while less suseptable to delays, requires data with a high density of tranitions to reduce the likelyhood of a desyncronisation event.
	Becuase delays in the data are possible, the latter option has been selected.

	\subsection{The Role of Scrambling Data in the VELO}
		
		For the reasons described in Section \ref{sec:scrambling_algorithms}, it is nessesary to ensure that the data has large density of transitions before being transmitted from the front-end detector to the DAQ modual.
		However, as the majority of SP hitmaps are empty, the data has a large bais towards 0s.
		This reduces the frequancy of transitions in the data - increasing the probability of a desyncronisation event.
		It is therefor nesseccary to scramble the data pria to transmition and descramble the data in the DAQ FPGA.
		\par
		Scrambleing and later descrambleing the data is not a trivial exercise.
		The scrambleing (TX) modual and descrambling (RX) modual must use a sycronised \textit{`key'}, derived from the previous states of the data.
		There are two options when generating this \textit{`key'}:

		\begin{description}
			\item[Additive] The \textit{`key'} is generated by evolving the previous \textit{`key'} at each itteration of data using the incoming frame.
			\item[Multiplicative] The  \textit{`key'} is generated from the previos $n$ frames. (Here $n$ is a variable specific to the algorithm).
		\end{description}

	\subsection{Scrambler Options}
	\label{sub:scrambler_options}

		Three scrambling algorithums have been concidered:

		\begin{description}
			\item[Additive Scrambler] \hfill \\
				This algoritum is simple and easy to use, however has the drawback of time dependance.
				If a desyncronisation event occours, all subsequent data is rendered unrecoverable untill such time as a global reset signal is sent.
				Further adding to the drawbacks, if a data packet is not sent from the TX during any clock cycle the RX descrambler will still evolve its descramble key - the TX sccrambler, however, will not.
				This will ofcourse desyncronise the \textit{`keys'}, and as before all subsequent data is lost.

			\item[Intermediate Scrambler] \hfill \\
				Deriving its name from being the second algorithum under concideration, the Intermediate Scrambler is a \textbf{multiplicative} algorithm. 
				The \textit{`key'} is generated from the current incoming frame and the previous frame.
				Therefor, in the event of desyncronisation, only two frames are lost before the \textit{`key'} is automatically recovered.
				This is a significant improvment over the Additive Scrambler.

			\item[VeloPix Scrambler] \hfill \\
				Named as, at the time of the start of the project \textit{(September 2015)}, this algorithum is the current preffered option by the VeloPix team; 
				this too is a \textbf{multiplicative} algorithm.
				The \textit{`key'} is, again like the Intermediate Scrambler, generaged from the currect and previous data frame.
				The VeloPix Scrambler differse from the Intermediate scrambler as it aims to more effeciently scramble the data.
		\end{description}

	\subsection{Algorithm Analysis}

		Intuitively, one can assume that fully scrambled data will be indistinguisable from randomly generated data. 
		For this reason, the three algorithm are not only tested against eachother and the pre-scrambled data but also randomly generated binary.
		The randomly generated data was created using the Python \textit{`random'} library, selecting a \textit{`0'} or \textit{`1'} with probubility $1/2$ each.
		While the Python \textit{`random'} library is only sudo-random, on the scale of this example (i.e. $>$ 100,000 frames), this is by far sufficient.
		\par
		More mathematicaly rigorus, however, is to evaluade the system abstractly in the framework of statistical physics.
		In this abstraction, the ensemble is the 120 bit frame (with the header and parity removed); 
		microstates are the particular form of the frames;
		and macroscopic quantities can be calculated by averaging a large number of frames (i.e. the desync data).
		For the analysis outlined in section \ref{subsub:messurements_of_the_algorithms}, prediction will be made using these principles and outlined in section \ref{subsub:statistical_predictions}.

		\subsubsection{Messurements of the Algorithms} 
		\label{subsub:messurements_of_the_algorithms}

			To compare the effecincy of the three algorithums in section \ref{sub:scrambler_options}, the algorithums where run over the same unput data and compared for the following measures:

			\begin{description}
				\item[Number of Transitions Per Frame] \hfill \\

				\item[Common Bit Chain Length] \hfill \\

				\item[Total Bit Frequancy] \hfill \\
			\end{description}

		\subsubsection{Statistical Predictions} % (fold)
		\label{subsub:statistical_predictions}

		\subsubsection{Results of Analysis}

	\subsection{Conclusion}